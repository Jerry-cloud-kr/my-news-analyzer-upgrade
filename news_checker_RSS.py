import streamlit as st
from newspaper import Article, Config
from sentence_transformers import SentenceTransformer, util
import openai
from openai import OpenAI
import google.generativeai as genai
import feedparser
import requests
import urllib.parse # URL ì¸ì½”ë”©ì„ ìœ„í•´ ì¶”ê°€

# --- API Key ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (Secrets ìš°ì„ ) ---
# OpenAI
client_openai = None
OPENAI_API_KEY_Direct_Placeholder = "YOUR_OPENAI_KEY_PLACEHOLDER" # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ì‹¤ì œ í‚¤ë¥¼ ì—¬ê¸°ì—!
try:
    OPENAI_API_KEY_FROM_SECRETS = st.secrets["OPENAI_API_KEY"]
    if not OPENAI_API_KEY_FROM_SECRETS:
         st.error("âš ï¸ OpenAI API í‚¤ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ ê°’ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
         st.stop()
    client_openai = OpenAI(api_key=OPENAI_API_KEY_FROM_SECRETS)
except KeyError: # ë¡œì»¬ì—ì„œ st.secrets["OPENAI_API_KEY"]ê°€ ì—†ì„ ë•Œ
    if OPENAI_API_KEY_Direct_Placeholder == "YOUR_OPENAI_KEY_PLACEHOLDER" or not OPENAI_API_KEY_Direct_Placeholder:
        st.error("OpenAI API í‚¤ë¥¼ Secretsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ì½”ë“œ ìƒë‹¨ OPENAI_API_KEY_Direct_Placeholder ê°’ì„ ì‹¤ì œ í‚¤ë¡œ ì…ë ¥í•˜ê±°ë‚˜, ì•± ë°°í¬ í›„ Streamlit Community Cloudì˜ Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    else: # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ì‹¤ì œ í‚¤ê°€ í”Œë ˆì´ìŠ¤í™€ë”ì— ì…ë ¥ë˜ì—ˆë‹¤ê³  ê°€ì •
        st.warning("ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© OpenAI API í‚¤ê°€ ì½”ë“œì— ì§ì ‘ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. GitHub í‘¸ì‹œ ì „ ë°˜ë“œì‹œ Secrets ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ í‚¤ë¥¼ ì‚­ì œí•˜ì„¸ìš”.", icon="â—")
        client_openai = OpenAI(api_key=OPENAI_API_KEY_Direct_Placeholder)
except Exception as e:
    st.error(f"OpenAI API í‚¤/í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

if client_openai is None: # client_openaiê°€ ì–´ë–¤ ì´ìœ ë¡œë“  ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¤‘ë‹¨
    st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

# Google AI (Gemini)
GOOGLE_AI_API_KEY_Direct_Placeholder = "YOUR_GOOGLE_AI_KEY_PLACEHOLDER" # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ì‹¤ì œ í‚¤ë¥¼ ì—¬ê¸°ì—!
try:
    GOOGLE_AI_API_KEY_FROM_SECRETS = st.secrets["GOOGLE_AI_API_KEY"]
    if not GOOGLE_AI_API_KEY_FROM_SECRETS:
         st.error("âš ï¸ Google AI API í‚¤ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ ê°’ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
         st.stop()
    genai.configure(api_key=GOOGLE_AI_API_KEY_FROM_SECRETS)
except KeyError: # ë¡œì»¬ì—ì„œ st.secrets["GOOGLE_AI_API_KEY"]ê°€ ì—†ì„ ë•Œ
    if GOOGLE_AI_API_KEY_Direct_Placeholder == "YOUR_GOOGLE_AI_KEY_PLACEHOLDER" or not GOOGLE_AI_API_KEY_Direct_Placeholder:
        st.error("Google AI API í‚¤ë¥¼ Secretsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ì½”ë“œ ìƒë‹¨ì˜ GOOGLE_AI_API_KEY_Direct_Placeholder ê°’ì„ ì‹¤ì œ í‚¤ë¡œ ì…ë ¥í•˜ê±°ë‚˜, ì•± ë°°í¬ í›„ Streamlit Community Cloudì˜ Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    else: # ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ì‹¤ì œ í‚¤ê°€ í”Œë ˆì´ìŠ¤í™€ë”ì— ì…ë ¥ë˜ì—ˆë‹¤ê³  ê°€ì •
        st.warning("ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© Google AI API í‚¤ê°€ ì½”ë“œì— ì§ì ‘ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. GitHub í‘¸ì‹œ ì „ ë°˜ë“œì‹œ Secrets ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ í‚¤ë¥¼ ì‚­ì œí•˜ì„¸ìš”.", icon="â—")
        genai.configure(api_key=GOOGLE_AI_API_KEY_Direct_Placeholder)
except Exception as e:
    st.error(f"Google AI API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# --- Helper Functions ---
@st.cache_data # ë™ì¼ URL ë°˜ë³µ ìš”ì²­ ë°©ì§€
def get_final_url(url, timeout=10):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    try:
        response = requests.get(url, headers=headers, timeout=timeout, allow_redirects=True)
        response.raise_for_status() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì˜ˆì™¸ ë°œìƒ
        return response.url
    except requests.exceptions.RequestException as e:
        print(f"ìµœì¢… URL ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ({url}): {e}") # ì½˜ì†” ë¡œê·¸ëŠ” ìœ ì§€
        return url # ì‹¤íŒ¨ ì‹œ ì›ë˜ URL ë°˜í™˜ (newspaper3kê°€ ë‹¤ì‹œ ì‹œë„)
    except Exception as e:
        print(f"ìµœì¢… URL í™•ì¸ ì¤‘ ê¸°íƒ€ ì˜¤ë¥˜ ({url}): {e}") # ì½˜ì†” ë¡œê·¸ëŠ” ìœ ì§€
        return url

# --- AI ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ ---
def summarize_text_gemini(text_content):
    model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest', system_instruction="ë„ˆëŠ” ë‰´ìŠ¤ ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” AIì•¼.")
    prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°ê´€ì ì¸ ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì‹­ì‹œì˜¤. ìš”ì•½ì—ëŠ” ì£¼ìš” ì¸ë¬¼, ë°œìƒí•œ ì‚¬ê±´, ì¤‘ìš”í•œ ë°œì–¸, ê·¸ë¦¬ê³  ì‚¬ê±´ì˜ ë°°ê²½ ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì£¼ê´€ì ì¸ í•´ì„, í‰ê°€, ë˜ëŠ” ê¸°ì‚¬ì— ëª…ì‹œì ìœ¼ë¡œ ë“œëŸ¬ë‚˜ì§€ ì•Šì€ ì¶”ë¡ ì€ ë°°ì œí•˜ê³ , ì‚¬ì‹¤ ê´€ê³„ë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ” ë° ì§‘ì¤‘í•´ ì£¼ì‹­ì‹œì˜¤. ë¶„ëŸ‰ì€ í•œêµ­ì–´ ê¸°ì¤€ìœ¼ë¡œ ì•½ 3~5ë¬¸ì¥ (ë˜ëŠ” 100~150 ë‹¨ì–´) ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ ì£¼ì‹­ì‹œì˜¤.\n\nê¸°ì‚¬:\n{text_content}"
    try:
        response = model.generate_content(prompt,generation_config=genai.types.GenerationConfig(temperature=0.3))
        return response.text.strip()
    except Exception as e:
        st.warning("Gemini ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"Gemini ìš”ì•½ API ì˜¤ë¥˜: {e}")
        return "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

def detect_bias_openai(title, text_content):
    prompt = f"ë‹¤ìŒì€ ë‰´ìŠ¤ ì œëª©ê³¼ ë³¸ë¬¸ì…ë‹ˆë‹¤. ì œëª©ì´ ë³¸ë¬¸ ë‚´ìš©ì„ ì¶©ë¶„íˆ ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€, ì¤‘ìš”í•œ ë§¥ë½ì´ë‚˜ ì¸ë¬¼ì˜ ì…ì¥ì´ ì™œê³¡ë˜ê±°ë‚˜ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì¤˜.\n\nì œëª©: {title}\në³¸ë¬¸: {text_content}\n\në¶„ì„ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ 3~5ì¤„ë¡œ ì •ë¦¬í•´ì¤˜."
    try:
        completion = client_openai.chat.completions.create(model="gpt-4", messages=[{"role": "system", "content": "ë„ˆëŠ” ê³µì •í•œ ë‰´ìŠ¤ í”„ë ˆì´ë° ë¶„ì„ ë„ìš°ë¯¸ì•¼."}, {"role": "user", "content": prompt}])
        return completion.choices[0].message.content.strip()
    except Exception as e:
        st.warning("OpenAI í”„ë ˆì´ë° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"OpenAI í”„ë ˆì´ë° ë¶„ì„ API ì˜¤ë¥˜: {e}")
        return "í”„ë ˆì´ë° ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

def extract_keywords_gemini(article_text):
    model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest', system_instruction="You are an AI assistant specialized in extracting the most important keywords from news articles. Keywords should be nouns or core noun phrases. Respond only with the keywords, separated by commas.")
    user_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 5ê°œë§Œ ì¶”ì¶œí•˜ì—¬, ê° í‚¤ì›Œë“œë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n\nì˜ˆì‹œ ì‘ë‹µ:\ní‚¤ì›Œë“œ1,í•µì‹¬ ë‹¨ì–´,ì„¸ë²ˆì§¸ í‚¤ì›Œë“œ,ì¤‘ìš” ê°œë…,ë§ˆì§€ë§‰\n\nê¸°ì‚¬ ë³¸ë¬¸:\n{article_text}"
    try:
        response = model.generate_content(user_prompt, generation_config=genai.types.GenerationConfig(temperature=0.2))
        keywords_string = response.text.strip()
        if keywords_string:
            if "\n" in keywords_string: keywords_string = keywords_string.split("\n")[-1]
            if ":" in keywords_string: keywords_string = keywords_string.split(":")[-1].strip()
            return [kw.strip() for kw in keywords_string.split(',') if kw.strip()]
        return []
    except Exception as e:
        print(f"Gemini í‚¤ì›Œë“œ ì¶”ì¶œ API ì˜¤ë¥˜: {e}")
        st.warning("AI í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return []

# --- ìœ ì‚¬ë„ ì¸¡ì • ëª¨ë¸ ë¡œë“œ (í™œì„±í™”) ---
model_similarity = None
try:
    model_similarity = SentenceTransformer('all-MiniLM-L6-v2', device='cpu')
    if model_similarity:
        print("SentenceTransformer ëª¨ë¸ ë¡œë“œ ì„±ê³µ!")
    else:
        st.error("SentenceTransformer ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìœ¼ë‚˜ ëª…ì‹œì  ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•± ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        st.stop()
except Exception as e:
    st.error(f"SentenceTransformer ëª¨ë¸ ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.error("íŒ: ì´ ì˜¤ë¥˜ëŠ” ë³´í†µ torch, torchvision, torchaudio ë˜ëŠ” sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜/í˜¸í™˜ì„± ë¬¸ì œì…ë‹ˆë‹¤.")
    st.error("ì•±ì˜ Python ë²„ì „(Streamlit Cloud ì„¤ì •), requirements.txt (torch í¬í•¨ ì—¬ë¶€), packages.txt ë“±ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop() # ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨ ì‹œ ì•± ì¤‘ë‹¨

# --- ê¸°ì‚¬ ë¶„ì„ ë° ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ ---
def display_article_analysis_content(title_to_display, text_content, article_url):
    st.markdown("---")
    st.subheader("ğŸ“° ê¸°ì‚¬ ì œëª©")
    st.write(f"**{title_to_display}**")
    st.markdown(f"[ğŸ”— ê¸°ì‚¬ ì›ë¬¸ ë°”ë¡œê°€ê¸°]({article_url})", unsafe_allow_html=True)
    st.markdown("---")

    # Geminië¡œ ìš”ì•½
    st.subheader("ğŸ§¾ ë³¸ë¬¸ ìš”ì•½ (by Gemini AI)")
    with st.expander("âš ï¸ AI ìš”ì•½ì— ëŒ€í•œ ì¤‘ìš” ì•ˆë‚´ (í´ë¦­í•˜ì—¬ í™•ì¸)", expanded=False):
        st.markdown(""" **ì£¼ì˜: AI ê¸°ë°˜ ìš”ì•½ (Gemini)**\n\n* ë³¸ ìš”ì•½ì€ Gemini ëª¨ë¸ì„ í†µí•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ê¸°ì‚¬ì˜ ëª¨ë“  ë‚´ìš©ì„ ì™„ë²½í•˜ê²Œ ë°˜ì˜í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n* AIëŠ” í•™ìŠµ ë°ì´í„°ì˜ í•œê³„ë‚˜ ìš”ì•½ ê³¼ì •ì˜ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ë•Œë•Œë¡œ ë¶€ì •í™•í•œ ë‚´ìš©ì„ ì „ë‹¬í•˜ê±°ë‚˜ ì¤‘ìš”í•œ ë‚´ìš©ì„ ìƒëµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n* ì œê³µëœ ìš”ì•½ì€ ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê¸° ìœ„í•œ ì°¸ê³  ìë£Œë¡œë§Œ í™œìš©í•´ì£¼ì‹­ì‹œì˜¤.\n* ê¸°ì‚¬ì˜ ì „ì²´ì ì¸ ë§¥ë½ê³¼ ì •í™•í•œ ì •ë³´ í™•ì¸ì„ ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ì›ë¬¸ ê¸°ì‚¬ë¥¼ í•¨ê»˜ ì½ì–´ë³´ì‹œëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ìµœì¢…ì ì¸ ë‚´ìš©ì— ëŒ€í•œ íŒë‹¨ì€ ì‚¬ìš©ìì˜ ì±…ì„ì…ë‹ˆë‹¤. """)
    body_summary = summarize_text_gemini(text_content)
    if body_summary == "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.": st.error(body_summary)
    else: st.write(body_summary)
    st.markdown("---")

    # Geminië¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¹„êµ (*** ì—¬ê¸°ê°€ ìˆ˜ì •ëœ ë¶€ë¶„ ***)
    st.subheader("ğŸ” AI ì¶”ì¶œ ì£¼ìš” í‚¤ì›Œë“œ (í´ë¦­ ì‹œ Google ê²€ìƒ‰)")
    extracted_keywords = extract_keywords_gemini(text_content)

    if not extracted_keywords:
        st.info("â„¹ï¸ AIê°€ ë³¸ë¬¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆê±°ë‚˜, ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        keyword_links_html_list = []
        for kw in extracted_keywords:
            search_url_google = f"https://www.google.com/search?q={urllib.parse.quote_plus(kw)}"
            # HTML <a> íƒœê·¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ìƒˆ ì°½ì—ì„œ ì—´ë¦¬ë„ë¡ í•˜ê³ , ê°„ë‹¨í•œ ìŠ¤íƒ€ì¼ ì ìš©
            keyword_links_html_list.append(
                f"<a href='{search_url_google}' target='_blank' "
                f"style='margin-right: 7px; margin-bottom: 5px; padding: 3px 7px; "
                f"border: 1px solid #007bff; border-radius: 5px; color: #007bff; "
                f"text-decoration: none; display: inline-block;'>{kw}</a>"
            )
        
        st.markdown("AI(Gemini)ê°€ ë³¸ë¬¸ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œ:<br>" + "".join(keyword_links_html_list), unsafe_allow_html=True)

        missing_in_title = [kw for kw in extracted_keywords if kw.lower() not in title_to_display.lower()]
        if missing_in_title:
            missing_keyword_links_html_list = []
            for kw_missing in missing_in_title:
                search_url_google_missing = f"https://www.google.com/search?q={urllib.parse.quote_plus(kw_missing)}"
                missing_keyword_links_html_list.append(
                    f"<a href='{search_url_google_missing}' target='_blank' "
                    f"style='margin-right: 7px; margin-bottom: 5px; padding: 3px 7px; "
                    f"border: 1px solid #ffc107; border-radius: 5px; color: #c69500; "
                    f"text-decoration: none; display: inline-block;'>{kw_missing}</a>"
                )
            
            # st.warning ëŒ€ì‹  st.markdownì„ ì‚¬ìš©í•˜ì—¬ HTML ë§í¬ í¬í•¨
            warning_html_message = f"""
            <div style="background-color: #fff3cd; color: #856404; padding: 0.75rem 1.25rem; margin-top: 1rem; margin-bottom: 1rem; border: 1px solid transparent; border-radius: 0.25rem; border-color: #ffeeba;">
                â— AI ì¶”ì¶œ í‚¤ì›Œë“œ ì¤‘ ì¼ë¶€ê°€ ì œëª©ì— ë¹ ì ¸ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤:<br> {''.join(missing_keyword_links_html_list)}
            </div>
            """
            st.markdown(warning_html_message, unsafe_allow_html=True)

        elif extracted_keywords: # í‚¤ì›Œë“œê°€ ìˆì—ˆê³ , ì œëª©ì— ëª¨ë‘ ë°˜ì˜ëœ ê²½ìš°
            st.success("âœ… AI ì¶”ì¶œ í•µì‹¬ í‚¤ì›Œë“œê°€ ì œëª©ì— ì˜ ë°˜ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("---")
    # (*** ìˆ˜ì •ëœ ë¶€ë¶„ ì—¬ê¸°ê¹Œì§€ ***)

    # ìœ ì‚¬ë„ íŒë‹¨ (í™œì„±í™”)
    st.subheader("ğŸ“Š ì œëª©-ë³¸ë¬¸ìš”ì•½ ìœ ì‚¬ë„ íŒë‹¨")
    if model_similarity is not None:
        try:
            embeddings = model_similarity.encode([title_to_display, body_summary], convert_to_tensor=True)
            similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()

            similarity_threshold_high = 0.65; similarity_threshold_mid = 0.40
            if similarity > similarity_threshold_high: result_text, result_color = "âœ… **ë†’ìŒ**: ì œëª©ì´ ë³¸ë¬¸ ìš”ì•½ ë‚´ìš©ì„ ì˜ ë°˜ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.", "green"
            elif similarity > similarity_threshold_mid: result_text, result_color = "ğŸŸ¡ **ì¤‘ê°„**: ì œëª©ì´ ë³¸ë¬¸ ìš”ì•½ê³¼ ë‹¤ì†Œ ê´€ë ¨ì€ ìˆì§€ë§Œ, ë‚´ìš©ì´ ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "orange"
            else: result_text, result_color = "âš ï¸ **ë‚®ìŒ**: ì œëª©ì´ ë³¸ë¬¸ ìš”ì•½ ë‚´ìš©ê³¼ ë§ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚šì‹œì„±ì´ê±°ë‚˜ ë‹¤ë¥¸ ë‚´ìš©ì„ ë‹¤ë£° ê°€ëŠ¥ì„±ì„ í™•ì¸í•´ë³´ì„¸ìš”.", "red"

            st.markdown(f"<span style='color:{result_color};'>{result_text}</span> (ìœ ì‚¬ë„ ì ìˆ˜: {similarity:.2f})", unsafe_allow_html=True)
            st.caption(f"ì°¸ê³ : ìœ ì‚¬ë„ëŠ” ì œëª©ê³¼ AI ìš”ì•½ë¬¸ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì„ê³„ê°’(í˜„ì¬: ë†’ìŒ {similarity_threshold_high}, ì¤‘ê°„ {similarity_threshold_mid})ì— ë”°ë¼ í•´ì„ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        except Exception as e_sim:
            st.error(f"ìœ ì‚¬ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e_sim}")
            print(f"ìœ ì‚¬ë„ ë¶„ì„ ì˜¤ë¥˜: {e_sim}")
            st.info("â„¹ï¸ ìœ ì‚¬ë„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.info("â„¹ï¸ ì œëª©-ë³¸ë¬¸ ìœ ì‚¬ë„ ë¶„ì„ ê¸°ëŠ¥ì€ SentenceTransformer ëª¨ë¸ ë¡œë“œ ë¬¸ì œë¡œ ì¸í•´ í˜„ì¬ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    st.markdown("---")

    # GPTë¡œ í”„ë ˆì´ë° ë¶„ì„ (ìœ ì§€)
    st.subheader("ğŸ•µï¸ í”„ë ˆì´ë° ë¶„ì„ ê²°ê³¼ (by GPT)")
    with st.expander("âš ï¸ AI í”„ë ˆì´ë° ë¶„ì„ ì£¼ì˜ì‚¬í•­ (í´ë¦­í•˜ì—¬ í™•ì¸)"):
        st.markdown(""" **ì£¼ì˜: AI ê¸°ë°˜ í”„ë ˆì´ë° ë¶„ì„ (GPT)**\n\n* ë³¸ ë¶„ì„ì€ GPT ëª¨ë¸ì— ì˜í•´ ìˆ˜í–‰ë˜ì—ˆìœ¼ë©°, ì™„ë²½ì„±ì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n* AIëŠ” ë°ì´í„°ì™€ í•™ìŠµ ë°©ì‹ì— ë”°ë¼ í¸í–¥ëœ ê²°ê³¼ë¥¼ ì œì‹œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n* ì œê³µëœ ë¶„ì„ì€ ì°¸ê³  ìë£Œë¡œ í™œìš©í•˜ì‹œê³ , ìµœì¢…ì ì¸ íŒë‹¨ì€ ì‚¬ìš©ìì˜ ì±…ì„í•˜ì— ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤. """)
    framing_result = detect_bias_openai(title_to_display, text_content)
    if framing_result == "í”„ë ˆì´ë° ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.": st.error(framing_result)
    else: st.info(framing_result)

# --- newspaper3k Config ê°ì²´ ---
NEWS_CONFIG = Config()
NEWS_CONFIG.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
NEWS_CONFIG.request_timeout = 15
NEWS_CONFIG.memoize_articles = False
NEWS_CONFIG.fetch_images = False

# --- Streamlit ì•± UI êµ¬ì„± ---
st.set_page_config(page_title="ë‰´ìŠ¤ì½ì€ì²™ë°©ì§€ê¸° (AI)", page_icon="ğŸ§")
st.title("ğŸ§ ë‰´ìŠ¤ì½ì€ì²™ë°©ì§€ê¸°")
st.write("í‚¤ì›Œë“œ ê²€ìƒ‰ ë˜ëŠ” URL ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ AIì™€ í•¨ê»˜ ë¶„ì„í•´ë³´ì„¸ìš”!")
st.caption("ë³¸ë¬¸ ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œì€ Gemini AI, í”„ë ˆì´ë° ë¶„ì„ì€ OpenAI GPT, ìœ ì‚¬ë„ ë¶„ì„ì€ SentenceTransformerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ì…ë ¥ ë°©ì‹ ì„ íƒ (ì„¸ì…˜ ìƒíƒœë¥¼ ì‚¬ìš©í•˜ì—¬ ì„ íƒ ìœ ì§€)
if 'current_input_method' not in st.session_state:
    st.session_state.current_input_method = "í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰"

selected_input_method_on_page = st.radio( # ë³€ìˆ˜ëª… ë³€ê²½
    "ë‰´ìŠ¤ ê°€ì ¸ì˜¤ëŠ” ë°©ë²• ì„ íƒ:",
    ("í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰", "URL ì§ì ‘ ì…ë ¥"),
    key="input_method_selector_radio_key", # ê³ ìœ í•œ key
    horizontal=True,
    index=("í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰", "URL ì§ì ‘ ì…ë ¥").index(st.session_state.current_input_method)
)

# ë¼ë””ì˜¤ ë²„íŠ¼ ì„ íƒ ë³€ê²½ ì‹œ session_state ì—…ë°ì´íŠ¸ ë° rerun
if selected_input_method_on_page != st.session_state.current_input_method:
    st.session_state.current_input_method = selected_input_method_on_page
    if 'fetched_articles_for_selection_display' in st.session_state: # ê²€ìƒ‰ ê²°ê³¼ ì´ˆê¸°í™”
        del st.session_state.fetched_articles_for_selection_display
    if 'selected_article_to_show_url' in st.session_state: # ì„ íƒëœ URL í‘œì‹œ ì´ˆê¸°í™”
        del st.session_state.selected_article_to_show_url
    # "í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰" íƒ­ì˜ ì…ë ¥ê°’/ì„ íƒê°’ë„ ì´ˆê¸°í™”
    if 'keyword_search_input_final' in st.session_state: # í…ìŠ¤íŠ¸ ì…ë ¥ ì´ˆê¸°í™”
        st.session_state.keyword_search_input_final = ""
    if 'selected_article_display_title_key_tab1' in st.session_state: # selectbox ì„ íƒ ì´ˆê¸°í™”
        st.session_state.selected_article_display_title_key_tab1 = "ì„ íƒí•˜ì„¸ìš”..."
    st.rerun() # UIë¥¼ ê¹¨ë—í•˜ê²Œ ì •ë¦¬í•˜ê³  ë¼ë””ì˜¤ ë²„íŠ¼ ì„ íƒ ì¦‰ì‹œ ë°˜ì˜


if st.session_state.current_input_method == "í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰":
    st.subheader("ğŸ—‚ï¸ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ì°¾ì•„ë³´ê¸°")
    
    # í…ìŠ¤íŠ¸ ì…ë ¥ ê°’ì„ ì„¸ì…˜ ìƒíƒœë¡œ ê´€ë¦¬
    if 'keyword_search_input_final' not in st.session_state:
        st.session_state.keyword_search_input_final = ""

    search_query_keyword_tab = st.text_input(
        "ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:",
        value=st.session_state.keyword_search_input_final, # ì„¸ì…˜ ìƒíƒœ ê°’ ì‚¬ìš©
        placeholder="ì˜ˆ: ê¸€ë¡œë²Œ ê²½ì œ ë™í–¥",
        key="keyword_search_input_widget_key" # ìœ„ì ¯ ìì²´ì˜ í‚¤
    )
    # ì‚¬ìš©ìê°€ ì…ë ¥í•˜ë©´ ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
    if search_query_keyword_tab != st.session_state.keyword_search_input_final:
        st.session_state.keyword_search_input_final = search_query_keyword_tab
        # ì…ë ¥ ë³€ê²½ ì‹œ ì´ì „ ê²€ìƒ‰ ê²°ê³¼ ë° ì„ íƒ ì´ˆê¸°í™”
        if 'fetched_articles_for_selection_display' in st.session_state:
            del st.session_state.fetched_articles_for_selection_display
        if 'selected_article_display_title_key_tab1' in st.session_state:
            st.session_state.selected_article_display_title_key_tab1 = "ì„ íƒí•˜ì„¸ìš”..."
        # st.rerun() # ì¦‰ì‹œ ë°˜ì˜ì„ ì›í•˜ë©´ í™œì„±í™”, ë²„íŠ¼ í´ë¦­ ì‹œ ê²€ìƒ‰ì´ë©´ ë¶ˆí•„ìš”

    if st.button("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰", key="keyword_search_action_button_final", use_container_width=True):
        if not st.session_state.keyword_search_input_final: # ì„¸ì…˜ ìƒíƒœì˜ ê°’ìœ¼ë¡œ í™•ì¸
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            # ê²€ìƒ‰ ì‹œ ì´ì „ ê²°ê³¼ ì´ˆê¸°í™” (ì„ íƒ ì‚¬í•­, ì´ë¯¸ ì…ë ¥ ë³€ê²½ ì‹œ ì´ˆê¸°í™” ì¤‘)
            if 'fetched_articles_for_selection_display' in st.session_state:
                 del st.session_state.fetched_articles_for_selection_display
            st.session_state.selected_article_display_title_key_tab1 = "ì„ íƒí•˜ì„¸ìš”..."


            google_news_rss_url = f"https://news.google.com/rss/search?q={st.session_state.keyword_search_input_final}&hl=ko&gl=KR&ceid=KR:ko"
            temp_articles_list = []
            try:
                custom_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                with st.spinner(f"'{st.session_state.keyword_search_input_final}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ Google Newsì—ì„œ ê²€ìƒ‰í•˜ê³  ë§í¬ë¥¼ í™•ì¸ ì¤‘..."):
                    feed = feedparser.parse(google_news_rss_url, agent=custom_user_agent)
                    if feed.entries:
                        count = 0
                        for i, entry in enumerate(feed.entries[:15]):
                            if hasattr(entry, 'title') and hasattr(entry, 'link'):
                                final_url = get_final_url(entry.link)
                                if final_url:
                                    temp_articles_list.append({
                                        'display_option': f"{i+1}. {entry.title[:80]}{'...' if len(entry.title) > 80 else ''}",
                                        'original_title': entry.title,
                                        'url': final_url
                                    })
                                    count +=1
                        if temp_articles_list:
                             st.success(f"'{st.session_state.keyword_search_input_final}' ê´€ë ¨ ë‰´ìŠ¤ {count}ê±´ì˜ ë§í¬ë¥¼ í™•ì¸í–ˆìŠµë‹ˆë‹¤.")
                             st.session_state.fetched_articles_for_selection_display = temp_articles_list
                        else:
                            st.warning(f"'{st.session_state.keyword_search_input_final}' ê´€ë ¨ Google Newsì—ì„œ ìœ íš¨í•œ ê¸°ì‚¬ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜, ê¸°ì‚¬ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                            if 'fetched_articles_for_selection_display' in st.session_state:
                                del st.session_state.fetched_articles_for_selection_display
                    else:
                        st.warning(f"'{st.session_state.keyword_search_input_final}' ê´€ë ¨ Google Newsì—ì„œ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (HTTP Status: {feed.get('status', 'N/A')})")
                        if 'fetched_articles_for_selection_display' in st.session_state:
                            del st.session_state.fetched_articles_for_selection_display
            except Exception as e:
                st.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                if 'fetched_articles_for_selection_display' in st.session_state:
                    del st.session_state.fetched_articles_for_selection_display

    if 'fetched_articles_for_selection_display' in st.session_state and st.session_state.fetched_articles_for_selection_display:
        st.markdown("---")

        selectbox_options = ["ì„ íƒí•˜ì„¸ìš”..."] + [item['display_option'] for item in st.session_state.fetched_articles_for_selection_display]

        # selectboxì˜ ì„ íƒ ìƒíƒœë„ ì„¸ì…˜ì—ì„œ ê´€ë¦¬
        if 'selected_article_display_title_key_tab1' not in st.session_state or \
           st.session_state.selected_article_display_title_key_tab1 not in selectbox_options: # ìƒˆ ê²€ìƒ‰ ê²°ê³¼ì— ì´ì „ ì„ íƒì´ ì—†ìœ¼ë©´ ì´ˆê¸°í™”
            st.session_state.selected_article_display_title_key_tab1 = selectbox_options[0]


        selected_display_title_option = st.selectbox(
            "í‘œì‹œëœ ëª©ë¡ì—ì„œ ê¸°ì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            options=selectbox_options,
            index=selectbox_options.index(st.session_state.selected_article_display_title_key_tab1),
            key="select_article_to_view_link_final"
        )
        if selected_display_title_option != st.session_state.selected_article_display_title_key_tab1:
            st.session_state.selected_article_display_title_key_tab1 = selected_display_title_option
            st.rerun()

        if st.session_state.selected_article_display_title_key_tab1 and st.session_state.selected_article_display_title_key_tab1 != "ì„ íƒí•˜ì„¸ìš”...":
            selected_article_data = next((item for item in st.session_state.fetched_articles_for_selection_display if item['display_option'] == st.session_state.selected_article_display_title_key_tab1), None)

            if selected_article_data:
                st.markdown("---")
                st.markdown(f"**ì„ íƒëœ ê¸°ì‚¬ (í´ë¦­ ì‹œ ì›ë¬¸ ì´ë™):**")
                st.markdown(f"### [{selected_article_data['original_title']}]({selected_article_data['url']})", unsafe_allow_html=True)
                st.info("ğŸ‘† ìœ„ ê¸°ì‚¬ ì œëª© ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ì›ë¬¸ì„ í™•ì¸í•˜ì‹  í›„, í•´ë‹¹ URLì„ ë³µì‚¬í•˜ì—¬ 'URL ì§ì ‘ ì…ë ¥' íƒ­ì— ë¶™ì—¬ë„£ê³  ë¶„ì„ì„ ì‹œì‘í•˜ì„¸ìš”.")
        st.markdown("---")

elif st.session_state.current_input_method == "URL ì§ì ‘ ì…ë ¥":
    st.subheader("ğŸ”— URL ì§ì ‘ ì…ë ¥í•˜ì—¬ ë¶„ì„í•˜ê¸°")
    url_direct_input_field_val = st.text_input(
        "ë¶„ì„í•  ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì „ì²´ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”:",
        placeholder="ì˜ˆ: https://www.example-news.com/news/article123",
        key="url_direct_input_field_main_key_final"
    )

    if st.button("ğŸš€ URL ë¶„ì„ ì‹œì‘", use_container_width=True, key="direct_url_analyze_button_main_action_key_final_action"):
        if not url_direct_input_field_val:
            st.warning("ë¶„ì„í•  ê¸°ì‚¬ì˜ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not (url_direct_input_field_val.startswith('http://') or url_direct_input_field_val.startswith('https://')):
            st.warning("ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            final_url_to_process = get_final_url(url_direct_input_field_val)

            try:
                with st.spinner(f"ê¸°ì‚¬ë¥¼ ê°€ì ¸ì™€ AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤... (URL: {final_url_to_process})"):
                    article = Article(final_url_to_process, config=NEWS_CONFIG, language='ko')
                    article.download()
                    article.parse()
                    if not article.title or not article.text or len(article.text) < 50:
                        st.error("ê¸°ì‚¬ ì œëª©ì´ë‚˜ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆê±°ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ URLì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    else:
                        display_article_analysis_content(article.title, article.text, final_url_to_process)
            except Exception as e:
                st.error(f"URL ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(f"ì „ì²´ ì˜¤ë¥˜: {e}")
                st.caption("URLì„ í™•ì¸í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê¸°ì‚¬ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”. ì¼ë¶€ ì›¹ì‚¬ì´íŠ¸ëŠ” ì™¸ë¶€ ì ‘ê·¼ì„ í†µí•œ ê¸°ì‚¬ ìˆ˜ì§‘ì„ í—ˆìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")