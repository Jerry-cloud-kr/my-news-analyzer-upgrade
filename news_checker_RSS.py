import streamlit as st
import pandas as pd
import os
from newspaper import Article, Config # newspaper Config ì¶”ê°€
# from sentence_transformers import SentenceTransformer, util # <<<<<<<<<<< ì¼ë‹¨ ì£¼ì„ ì²˜ë¦¬
import openai # OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬
from openai import OpenAI # OpenAI í´ë¼ì´ì–¸íŠ¸ í´ëž˜ìŠ¤ ìž„í¬íŠ¸
import google.generativeai as genai
import feedparser # í‚¤ì›Œë“œ ê²€ìƒ‰ ê¸°ëŠ¥ì— í•„ìš”
import requests # Naver ë‰´ìŠ¤ ì›ë¬¸ ë§í¬ ì¶”ì¶œì— í•„ìš”
from bs4 import BeautifulSoup # Naver ë‰´ìŠ¤ ì›ë¬¸ ë§í¬ ì¶”ì¶œì— í•„ìš”

# --- OpenAI API Key ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (Secrets ì‚¬ìš©) ---
client_openai = None 
OPENAI_API_KEY_Direct_Placeholder = "YOUR_OPENAI_KEY_PLACEHOLDER" 

try:
    OPENAI_API_KEY_FROM_SECRETS = st.secrets["OPENAI_API_KEY"]
    if not OPENAI_API_KEY_FROM_SECRETS:
         st.error("âš ï¸ OpenAI API í‚¤ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ ê°’ì´ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤. ì•± ì„¤ì •ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”.")
         st.stop()
    client_openai = OpenAI(api_key=OPENAI_API_KEY_FROM_SECRETS) 
except KeyError:
    if OPENAI_API_KEY_Direct_Placeholder == "YOUR_OPENAI_KEY_PLACEHOLDER" or not OPENAI_API_KEY_Direct_Placeholder:
        st.error("OpenAI API í‚¤ë¥¼ Streamlit Secretsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ì½”ë“œ ìƒë‹¨ì˜ OPENAI_API_KEY_Direct_Placeholder ê°’ì„ ì‹¤ì œ í‚¤ë¡œ ìž…ë ¥í•˜ê±°ë‚˜, ì•± ë°°í¬ í›„ Streamlit Community Cloudì˜ Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    else: 
        st.warning("ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© OpenAI API í‚¤ê°€ ì½”ë“œì— ì§ì ‘ ì„¤ì •ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. GitHubì— ë°°í¬/í‘¸ì‹œí•˜ê¸° ì „ì— ì´ ë¶€ë¶„ì„ ë°˜ë“œì‹œ Streamlit Secrets ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ í‚¤ë¥¼ ì‚­ì œí•˜ì„¸ìš”.", icon="â—")
        client_openai = OpenAI(api_key=OPENAI_API_KEY_Direct_Placeholder)
except Exception as e:
    st.error(f"OpenAI API í‚¤ ì„¤ì • ë˜ëŠ” í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {e}")
    st.stop()

if client_openai is None: 
    st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í‚¤ ì„¤ì •ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- Google AI API Key ì„¤ì • (Secrets ì‚¬ìš©) ---
GOOGLE_AI_API_KEY_Direct_Placeholder = "YOUR_GOOGLE_AI_KEY_PLACEHOLDER" 
try:
    GOOGLE_AI_API_KEY_FROM_SECRETS = st.secrets["GOOGLE_AI_API_KEY"]
    if not GOOGLE_AI_API_KEY_FROM_SECRETS:
         st.error("âš ï¸ Google AI API í‚¤ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ ê°’ì´ ë¹„ì–´ìžˆìŠµë‹ˆë‹¤. ì•± ì„¤ì •ì—ì„œ í™•ì¸í•´ì£¼ì„¸ìš”.")
         st.stop()
    genai.configure(api_key=GOOGLE_AI_API_KEY_FROM_SECRETS)
except KeyError:
    if GOOGLE_AI_API_KEY_Direct_Placeholder == "YOUR_GOOGLE_AI_KEY_PLACEHOLDER" or not GOOGLE_AI_API_KEY_Direct_Placeholder:
        st.error("Google AI API í‚¤ë¥¼ Streamlit Secretsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ë¥¼ ì›í•˜ì‹œë©´ ì½”ë“œ ìƒë‹¨ì˜ GOOGLE_AI_API_KEY_Direct_Placeholder ê°’ì„ ì‹¤ì œ í‚¤ë¡œ ìž…ë ¥í•˜ê±°ë‚˜, ì•± ë°°í¬ í›„ Streamlit Community Cloudì˜ Secrets ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")
        st.stop()
    else: 
        st.warning("ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© Google AI API í‚¤ê°€ ì½”ë“œì— ì§ì ‘ ì„¤ì •ë˜ì–´ ìžˆìŠµë‹ˆë‹¤. GitHubì— ë°°í¬/í‘¸ì‹œí•˜ê¸° ì „ì— ì´ ë¶€ë¶„ì„ ë°˜ë“œì‹œ Streamlit Secrets ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ê±°ë‚˜ í‚¤ë¥¼ ì‚­ì œí•˜ì„¸ìš”.", icon="â—")
        genai.configure(api_key=GOOGLE_AI_API_KEY_Direct_Placeholder)
except Exception as e:
    st.error(f"Google AI API í‚¤ ì„¤ì • ì¤‘ ì˜¤ë¥˜: {e}")
    st.stop()

# --- Naver ë‰´ìŠ¤ ì›ë¬¸ ë§í¬ ì¶”ì¶œ í•¨ìˆ˜ ---
@st.cache_data # ê²°ê³¼ ìºì‹± (ë™ì¼ URLì— ëŒ€í•´ ë°˜ë³µ í˜¸ì¶œ ë°©ì§€)
def get_original_url_from_naver_news(naver_url):
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
    }
    try:
        response = requests.get(naver_url, headers=headers, timeout=10)
        response.raise_for_status() 
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # ì¼ë°˜ì ì¸ 'ê¸°ì‚¬ì›ë¬¸' ë§í¬ ì„ íƒìž (Naver êµ¬ì¡° ë³€ê²½ ì‹œ ì—…ë°ì´íŠ¸ í•„ìš”)
        original_link_tag = soup.select_one("a.media_end_head_origin_link_text")
        
        if original_link_tag and original_link_tag.get('href'):
            return original_link_tag['href']
        
        # ì¶”ê°€ì ì¸ ì„ íƒìž ì‹œë„ (ì˜ˆì‹œ)
        # press_logo = soup.select_one("div.press_logo img")
        # if press_logo and press_logo.parent.name == 'a' and press_logo.parent.get('href'):
        #     return press_logo.parent['href']
            
        print(f"Naver 'ê¸°ì‚¬ì›ë¬¸' ë§í¬ ìžë™ ì¶”ì¶œ ì‹¤íŒ¨: {naver_url}")
        return None 
    except requests.exceptions.RequestException as e:
        print(f"Naver ë‰´ìŠ¤ íŽ˜ì´ì§€ ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ({naver_url}): {e}")
        return None
    except Exception as e:
        print(f"Naver ë‰´ìŠ¤ íŒŒì‹± ì¤‘ ê¸°íƒ€ ì˜¤ë¥˜ ({naver_url}): {e}")
        return None

# --- AI ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ ---
def summarize_text_gemini(text_content):
    model = genai.GenerativeModel(
        model_name='gemini-1.5-flash-latest',
        system_instruction="ë„ˆëŠ” ë‰´ìŠ¤ ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” AIì•¼."
    )
    prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°ê´€ì ì¸ ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì‹­ì‹œì˜¤. ìš”ì•½ì—ëŠ” ì£¼ìš” ì¸ë¬¼, ë°œìƒí•œ ì‚¬ê±´, ì¤‘ìš”í•œ ë°œì–¸, ê·¸ë¦¬ê³  ì‚¬ê±´ì˜ ë°°ê²½ ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì£¼ê´€ì ì¸ í•´ì„, í‰ê°€, ë˜ëŠ” ê¸°ì‚¬ì— ëª…ì‹œì ìœ¼ë¡œ ë“œëŸ¬ë‚˜ì§€ ì•Šì€ ì¶”ë¡ ì€ ë°°ì œí•˜ê³ , ì‚¬ì‹¤ ê´€ê³„ë¥¼ ëª…í™•ížˆ ì „ë‹¬í•˜ëŠ” ë° ì§‘ì¤‘í•´ ì£¼ì‹­ì‹œì˜¤. ë¶„ëŸ‰ì€ í•œêµ­ì–´ ê¸°ì¤€ìœ¼ë¡œ ì•½ 3~5ë¬¸ìž¥ (ë˜ëŠ” 100~150 ë‹¨ì–´) ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ìž‘ì„±í•´ ì£¼ì‹­ì‹œì˜¤.\n\nê¸°ì‚¬:\n{text_content}"
    try:
        response = model.generate_content(prompt,generation_config=genai.types.GenerationConfig(temperature=0.3))
        return response.text.strip()
    except Exception as e:
        st.warning("ìš”ì•½ ìƒì„± ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"Gemini ìš”ì•½ API ì˜¤ë¥˜: {e}")
        return "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

def detect_bias_openai(title, text_content):
    prompt = f"ë‹¤ìŒì€ ë‰´ìŠ¤ ì œëª©ê³¼ ë³¸ë¬¸ìž…ë‹ˆë‹¤. ì œëª©ì´ ë³¸ë¬¸ ë‚´ìš©ì„ ì¶©ë¶„ížˆ ë°˜ì˜í•˜ê³  ìžˆëŠ”ì§€, ì¤‘ìš”í•œ ë§¥ë½ì´ë‚˜ ì¸ë¬¼ì˜ ìž…ìž¥ì´ ì™œê³¡ë˜ê±°ë‚˜ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì¤˜.\n\nì œëª©: {title}\në³¸ë¬¸: {text_content}\n\në¶„ì„ ê²°ê³¼ë¥¼ ê°„ë‹¨ížˆ 3~5ì¤„ë¡œ ì •ë¦¬í•´ì¤˜."
    try:
        completion = client_openai.chat.completions.create(model="gpt-4", messages=[{"role": "system", "content": "ë„ˆëŠ” ê³µì •í•œ ë‰´ìŠ¤ í”„ë ˆì´ë° ë¶„ì„ ë„ìš°ë¯¸ì•¼."}, {"role": "user", "content": prompt}])
        return completion.choices[0].message.content.strip()
    except Exception as e:
        st.warning("í”„ë ˆì´ë° ë¶„ì„ ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"OpenAI í”„ë ˆì´ë° ë¶„ì„ API ì˜¤ë¥˜: {e}")
        return "í”„ë ˆì´ë° ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

def extract_keywords_gemini(article_text):
    model = genai.GenerativeModel(
        model_name='gemini-1.5-flash-latest',
        system_instruction="You are an AI assistant specialized in extracting the most important keywords from news articles. Keywords should be nouns or core noun phrases. Respond only with the keywords, separated by commas."
    )
    user_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ê°€ìž¥ ì¤‘ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 5ê°œë§Œ ì¶”ì¶œí•˜ì—¬, ê° í‚¤ì›Œë“œë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•œ í•˜ë‚˜ì˜ ë¬¸ìžì—´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¬¸ìž¥ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n\nì˜ˆì‹œ ì‘ë‹µ:\ní‚¤ì›Œë“œ1,í•µì‹¬ ë‹¨ì–´,ì„¸ë²ˆì§¸ í‚¤ì›Œë“œ,ì¤‘ìš” ê°œë…,ë§ˆì§€ë§‰\n\nê¸°ì‚¬ ë³¸ë¬¸:\n{article_text}"
    try:
        response = model.generate_content(user_prompt, generation_config=genai.types.GenerationConfig(temperature=0.2))
        keywords_string = response.text.strip()
        if keywords_string:
            if "\n" in keywords_string: keywords_string = keywords_string.split("\n")[-1]
            if ":" in keywords_string: keywords_string = keywords_string.split(":")[-1].strip()
            return [kw.strip() for kw in keywords_string.split(',') if kw.strip()]
        return []
    except Exception as e:
        print(f"Gemini í‚¤ì›Œë“œ ì¶”ì¶œ API ì˜¤ë¥˜: {e}")
        st.warning("AI í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return []

# --- ìœ ì‚¬ë„ ì¸¡ì • ëª¨ë¸ ë¡œë“œ (ì¼ë‹¨ ì£¼ì„ ì²˜ë¦¬) ---
# model_similarity = None 
# try:
#     model_similarity = SentenceTransformer('all-MiniLM-L6-v2', device='cpu') 
#     if model_similarity is None: 
#         st.error("SentenceTransformer ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìœ¼ë‚˜ ëª…ì‹œì  ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•± ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
#         st.stop()
# except Exception as e:
#     st.error(f"SentenceTransformer ëª¨ë¸ ë¡œë“œ ì¤‘ ì˜¤ë¥˜: {e}")
#     st.error("íŒ: ì´ ì˜¤ë¥˜ëŠ” ë³´í†µ torch ë˜ëŠ” sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜/í˜¸í™˜ì„± ë¬¸ì œìž…ë‹ˆë‹¤.")
#     st.info("ìœ ì‚¬ë„ ë¶„ì„ ê¸°ëŠ¥ ì—†ì´ ì•±ì„ ê³„ì† ì‚¬ìš©í•˜ì‹œë ¤ë©´ ì½”ë“œì—ì„œ í•´ë‹¹ ëª¨ë¸ ë¡œë“œ ë¶€ë¶„ì„ ë‹¤ì‹œ ì£¼ì„ ì²˜ë¦¬í•´ì£¼ì„¸ìš”.")
#     st.stop()

# --- ê¸°ì‚¬ ë¶„ì„ ë° ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ ---
def display_article_analysis_content(title_to_display, text_content, article_url):
    st.markdown("---")
    st.subheader("ðŸ“° ê¸°ì‚¬ ì œëª©")
    st.write(f"**{title_to_display}**")
    st.markdown(f"[ðŸ”— ê¸°ì‚¬ ì›ë¬¸ ë°”ë¡œê°€ê¸°]({article_url})", unsafe_allow_html=True) # ì—¬ê¸°ì„œ article_urlì€ ìµœì¢… ë¶„ì„ ëŒ€ìƒ URL
    st.markdown("---")

    # Geminië¡œ ìš”ì•½
    st.subheader("ðŸ§¾ ë³¸ë¬¸ ìš”ì•½ (by Gemini AI)")
    with st.expander("âš ï¸ AI ìš”ì•½ì— ëŒ€í•œ ì¤‘ìš” ì•ˆë‚´ (í´ë¦­í•˜ì—¬ í™•ì¸)", expanded=False):
        st.markdown(""" **ì£¼ì˜: AI ê¸°ë°˜ ìš”ì•½ (Gemini)**\n\n* ë³¸ ìš”ì•½ì€ Gemini ëª¨ë¸ì„ í†µí•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ê¸°ì‚¬ì˜ ëª¨ë“  ë‚´ìš©ì„ ì™„ë²½í•˜ê²Œ ë°˜ì˜í•˜ì§€ ëª»í•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n* AIëŠ” í•™ìŠµ ë°ì´í„°ì˜ í•œê³„ë‚˜ ìš”ì•½ ê³¼ì •ì˜ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ë•Œë•Œë¡œ ë¶€ì •í™•í•œ ë‚´ìš©ì„ ì „ë‹¬í•˜ê±°ë‚˜ ì¤‘ìš”í•œ ë‚´ìš©ì„ ìƒëžµí•  ìˆ˜ ìžˆìŠµë‹ˆë‹¤.\n* ì œê³µëœ ìš”ì•½ì€ ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê¸° ìœ„í•œ ì°¸ê³  ìžë£Œë¡œë§Œ í™œìš©í•´ì£¼ì‹­ì‹œì˜¤.\n* ê¸°ì‚¬ì˜ ì „ì²´ì ì¸ ë§¥ë½ê³¼ ì •í™•í•œ ì •ë³´ í™•ì¸ì„ ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ì›ë¬¸ ê¸°ì‚¬ë¥¼ í•¨ê»˜ ì½ì–´ë³´ì‹œëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ìµœì¢…ì ì¸ ë‚´ìš©ì— ëŒ€í•œ íŒë‹¨ì€ ì‚¬ìš©ìžì˜ ì±…ìž„ìž…ë‹ˆë‹¤. """)
    body_summary = summarize_text_gemini(text_content)
    st.write(body_summary)
    st.markdown("---")

    # Geminië¡œ í‚¤ì›Œë“œ ì¶”ì¶œ ë° ë¹„êµ
    st.subheader("ðŸ” AI ì¶”ì¶œ ì£¼ìš” í‚¤ì›Œë“œì™€ ì œëª© ë¹„êµ (by Gemini AI)")
    extracted_keywords = extract_keywords_gemini(text_content)
    if not extracted_keywords:
        st.info("â„¹ï¸ AIê°€ ë³¸ë¬¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆê±°ë‚˜, ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.caption(f"AI(Gemini)ê°€ ë³¸ë¬¸ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œ: **{', '.join(extracted_keywords)}**")
        missing_in_title = [kw for kw in extracted_keywords if kw.lower() not in title_to_display.lower()]
        if missing_in_title:
            st.warning(f"â— AI ì¶”ì¶œ í‚¤ì›Œë“œ ì¤‘ ì¼ë¶€ê°€ ì œëª©ì— ë¹ ì ¸ìžˆì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤: **{', '.join(missing_in_title)}**")
        else:
            st.success("âœ… AI ì¶”ì¶œ í•µì‹¬ í‚¤ì›Œë“œê°€ ì œëª©ì— ìž˜ ë°˜ì˜ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.")
    st.markdown("---")
    
    # ìœ ì‚¬ë„ íŒë‹¨ (ì¼ë‹¨ ì£¼ì„ ì²˜ë¦¬)
    st.subheader("ðŸ“Š ì œëª©-ë³¸ë¬¸ìš”ì•½ ìœ ì‚¬ë„ íŒë‹¨ (í˜„ìž¬ ë¹„í™œì„±í™”)")
    st.info("â„¹ï¸ ì œëª©-ë³¸ë¬¸ ìœ ì‚¬ë„ ë¶„ì„ ê¸°ëŠ¥ì€ í˜„ìž¬ SentenceTransformer ëª¨ë¸ ë¡œë“œ ì˜¤ë¥˜ë¡œ ì¸í•´ ë¹„í™œì„±í™”ë˜ì–´ ìžˆìŠµë‹ˆë‹¤.")
    st.markdown("---")

    # GPTë¡œ í”„ë ˆì´ë° ë¶„ì„ (ìœ ì§€)
    st.subheader("ðŸ•µï¸ í”„ë ˆì´ë° ë¶„ì„ ê²°ê³¼ (by GPT)")
    with st.expander("âš ï¸ AI í”„ë ˆì´ë° ë¶„ì„ ì£¼ì˜ì‚¬í•­ (í´ë¦­í•˜ì—¬ í™•ì¸)"):
        st.markdown(""" **ì£¼ì˜: AI ê¸°ë°˜ í”„ë ˆì´ë° ë¶„ì„ (GPT)**\n\n* ë³¸ ë¶„ì„ì€ GPT ëª¨ë¸ì— ì˜í•´ ìˆ˜í–‰ë˜ì—ˆìœ¼ë©°, ì™„ë²½ì„±ì„ ë³´ìž¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n* AIëŠ” ë°ì´í„°ì™€ í•™ìŠµ ë°©ì‹ì— ë”°ë¼ íŽ¸í–¥ëœ ê²°ê³¼ë¥¼ ì œì‹œí•  ìˆ˜ë„ ìžˆìŠµë‹ˆë‹¤.\n* ì œê³µëœ ë¶„ì„ì€ ì°¸ê³  ìžë£Œë¡œ í™œìš©í•˜ì‹œê³ , ìµœì¢…ì ì¸ íŒë‹¨ì€ ì‚¬ìš©ìžì˜ ì±…ìž„í•˜ì— ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤. """)
    framing_result = detect_bias_openai(title_to_display, text_content)
    st.info(framing_result)

# --- newspaper3k Config ê°ì²´ (ì „ì—­ ë˜ëŠ” í•„ìš”ì‹œ ìƒì„±) ---
NEWS_CONFIG = Config()
NEWS_CONFIG.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
NEWS_CONFIG.request_timeout = 15

# --- Streamlit ì•± UI êµ¬ì„± ---
st.set_page_config(page_title="ë‰´ìŠ¤ì½ì€ì²™ë°©ì§€ê¸° (í•˜ì´ë¸Œë¦¬ë“œ AI)", page_icon="ðŸ§")
st.title("ðŸ§ ë‰´ìŠ¤ì½ì€ì²™ë°©ì§€ê¸°")
st.write("í‚¤ì›Œë“œ ê²€ìƒ‰ ë˜ëŠ” URL ì§ì ‘ ìž…ë ¥ìœ¼ë¡œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ AIì™€ í•¨ê»˜ ë¶„ì„í•´ë³´ì„¸ìš”!")
st.caption("ë³¸ë¬¸ ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œì€ Gemini AI, í”„ë ˆì´ë° ë¶„ì„ì€ OpenAI GPTë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

input_tab1, input_tab2 = st.tabs(["ðŸ—‚ï¸ í‚¤ì›Œë“œ/RSSí”¼ë“œë¡œ ë‰´ìŠ¤ ê²€ìƒ‰/ë¶„ì„", "ðŸ”— URL ì§ì ‘ ìž…ë ¥/ë¶„ì„"])

with input_tab1:
    st.subheader("í‚¤ì›Œë“œ ë˜ëŠ” RSS í”¼ë“œ URLë¡œ ë‰´ìŠ¤ ì°¾ì•„ ë¶„ì„í•˜ê¸°")
    search_type_tab1 = st.radio( "ê²€ìƒ‰/ìž…ë ¥ íƒ€ìž… ì„ íƒ:", ("í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰", "RSS í”¼ë“œ URL ì§ì ‘ ìž…ë ¥"), key="search_type_tab1", horizontal=True)

    if search_type_tab1 == "í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰":
        input_label_tab1 = "ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ìž…ë ¥í•˜ì„¸ìš”:"
        input_placeholder_tab1 = "ì˜ˆ: ì• í”Œ AI ì „ëžµ"
    else: 
        input_label_tab1 = "ë‰´ìŠ¤ RSS í”¼ë“œì˜ ì „ì²´ URLì„ ìž…ë ¥í•˜ì„¸ìš”:"
        input_placeholder_tab1 = "ì˜ˆ: https://www.chosun.com/arc/outboundfeeds/rss/?outputType=xml"
    rss_or_keyword_input_tab1 = st.text_input(input_label_tab1, placeholder=input_placeholder_tab1, key="rss_or_keyword_input_tab1")

    if st.button("ðŸ“° ë‰´ìŠ¤ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°", key="fetch_list_button_tab1", use_container_width=True):
        article_options_tab1 = {} 
        if not rss_or_keyword_input_tab1:
            st.warning("í‚¤ì›Œë“œ ë˜ëŠ” RSS í”¼ë“œ URLì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            feed_url_to_parse = None 
            if search_type_tab1 == "RSS í”¼ë“œ URL ì§ì ‘ ìž…ë ¥":
                if not (rss_or_keyword_input_tab1.startswith('http://') or rss_or_keyword_input_tab1.startswith('https://')):
                    st.warning("ì˜¬ë°”ë¥¸ RSS í”¼ë“œ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œìž‘í•´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    feed_url_to_parse = rss_or_keyword_input_tab1
                feed_source_name = "ìž…ë ¥í•˜ì‹  RSS í”¼ë“œ"
            elif search_type_tab1 == "í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰":
                feed_url_to_parse = f"https://news.google.com/rss/search?q={rss_or_keyword_input_tab1}&hl=ko&gl=KR&ceid=KR:ko"
                feed_source_name = f"'{rss_or_keyword_input_tab1}' ê´€ë ¨ Google News"

            if feed_url_to_parse: 
                try:
                    with st.spinner(f"{feed_source_name}ì—ì„œ ë‰´ìŠ¤ë¥¼ ê°€ì ¸ì˜¤ëŠ” ì¤‘..."):
                        feed = feedparser.parse(feed_url_to_parse)
                    if feed.entries:
                        for entry in feed.entries[:30]: 
                            if hasattr(entry, 'title') and hasattr(entry, 'link'):
                                article_options_tab1[entry.title] = entry.link
                        if article_options_tab1:
                             st.success(f"{feed_source_name}ì—ì„œ {len(article_options_tab1)}ê±´ì˜ ê¸°ì‚¬ ì œëª©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        else:
                            st.warning(f"{feed_source_name}ì—ì„œ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜, ê¸°ì‚¬ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"{feed_source_name}ì—ì„œ ê¸°ì‚¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                except Exception as e:
                    st.error(f"{search_type_tab1} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        
        if article_options_tab1:
            st.session_state.article_options_for_analysis_tab1 = article_options_tab1
        else: 
            if 'article_options_for_analysis_tab1' in st.session_state:
                del st.session_state.article_options_for_analysis_tab1

    if 'article_options_for_analysis_tab1' in st.session_state and st.session_state.article_options_for_analysis_tab1:
        selected_title_tab1 = st.selectbox(
            "ë¶„ì„í•  ê¸°ì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”:",
            options=list(st.session_state.article_options_for_analysis_tab1.keys()),
            index=None,
            placeholder="ëª©ë¡ì—ì„œ ê¸°ì‚¬ë¥¼ ì„ íƒí•˜ì„¸ìš”...",
            key="selectbox_tab1"
        )
        if selected_title_tab1 and st.button("ðŸ‘† ì„ íƒí•œ ë‰´ìŠ¤ ë¶„ì„í•˜ê¸°", key="analyze_selected_button_tab1", use_container_width=True):
            url_to_analyze_initially = st.session_state.article_options_for_analysis_tab1[selected_title_tab1]
            st.info(f"ì„ íƒí•œ ê¸°ì‚¬ ë¶„ì„ ì¤‘: {selected_title_tab1}")
            
            actual_url_to_process = url_to_analyze_initially 
            if "news.naver.com" in url_to_analyze_initially:
                with st.spinner("Naver ë‰´ìŠ¤ ê¸°ì‚¬ ì›ë¬¸ ë§í¬ë¥¼ ì°¾ëŠ” ì¤‘..."):
                    original_url = get_original_url_from_naver_news(url_to_analyze_initially)
                if original_url:
                    st.info(f"Naver ë‰´ìŠ¤ì—ì„œ ì¶”ì¶œëœ ì›ë¬¸ ë§í¬: {original_url}")
                    actual_url_to_process = original_url
                else:
                    st.warning("Naver ë‰´ìŠ¤ì—ì„œ ì›ë¬¸ ë§í¬ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Naver ë§í¬ë¡œ ë¶„ì„ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            
            try:
                with st.spinner(f"'{selected_title_tab1}' ê¸°ì‚¬ë¥¼ ê°€ì ¸ì™€ AIê°€ ë¶„ì„ ì¤‘ìž…ë‹ˆë‹¤... (URL: {actual_url_to_process})"):
                    article = Article(actual_url_to_process, config=NEWS_CONFIG, language='ko') 
                    article.download()
                    article.parse()
                    if not article.title or not article.text or len(article.text) < 50:
                        st.error("ì„ íƒí•œ ê¸°ì‚¬ì˜ ì œëª©ì´ë‚˜ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆê±°ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤.")
                    else:
                        title_for_analysis = article.title if article.title else selected_title_tab1 
                        display_article_analysis_content(title_for_analysis, article.text, actual_url_to_process)
            except Exception as e:
                st.error(f"ì„ íƒí•œ ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

with input_tab2:
    st.subheader("URLë¡œ ì§ì ‘ ë‰´ìŠ¤ ë¶„ì„í•˜ê¸°")
    url_direct_input_tab2 = st.text_input("ë¶„ì„í•  ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì „ì²´ URLì„ ìž…ë ¥í•´ì£¼ì„¸ìš”:", placeholder="ì˜ˆ: https://www.example-news.com/news/article123", key="url_direct_input_tab2")

    if st.button("ðŸš€ URL ë¶„ì„ ì‹œìž‘", use_container_width=True, key="direct_url_analyze_button_tab2"):
        if not url_direct_input_tab2:
            st.warning("ë¶„ì„í•  ê¸°ì‚¬ì˜ URLì„ ìž…ë ¥í•´ì£¼ì„¸ìš”.")
        elif not (url_direct_input_tab2.startswith('http://') or url_direct_input_tab2.startswith('https://')):
            st.warning("ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œìž‘í•´ì•¼ í•©ë‹ˆë‹¤.")
        else:
            st.info(f"ìž…ë ¥í•˜ì‹  URLì˜ ê¸°ì‚¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤: {url_direct_input_tab2}")
            
            actual_url_to_process = url_direct_input_tab2 
            if "news.naver.com" in url_direct_input_tab2:
                with st.spinner("Naver ë‰´ìŠ¤ ê¸°ì‚¬ ì›ë¬¸ ë§í¬ë¥¼ ì°¾ëŠ” ì¤‘..."):
                    original_url = get_original_url_from_naver_news(url_direct_input_tab2)
                if original_url:
                    st.info(f"Naver ë‰´ìŠ¤ì—ì„œ ì¶”ì¶œëœ ì›ë¬¸ ë§í¬: {original_url}")
                    actual_url_to_process = original_url
                else:
                    st.warning("Naver ë‰´ìŠ¤ì—ì„œ ì›ë¬¸ ë§í¬ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. Naver ë§í¬ë¡œ ë¶„ì„ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            
            try:
                with st.spinner(f"ê¸°ì‚¬ë¥¼ ê°€ì ¸ì™€ AIê°€ ë¶„ì„ ì¤‘ìž…ë‹ˆë‹¤... (URL: {actual_url_to_process})"):
                    article = Article(actual_url_to_process, config=NEWS_CONFIG, language='ko')
                    article.download()
                    article.parse()
                    if not article.title or not article.text or len(article.text) < 50:
                        st.error("ê¸°ì‚¬ ì œëª©ì´ë‚˜ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆê±°ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ URLì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    else:
                        display_article_analysis_content(article.title, article.text, actual_url_to_process)
            except Exception as e:
                st.error(f"URL ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(f"ì „ì²´ ì˜¤ë¥˜: {e}") 
                st.caption("URLì„ í™•ì¸í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê¸°ì‚¬ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”. ì¼ë¶€ ì›¹ì‚¬ì´íŠ¸ëŠ” ì™¸ë¶€ ì ‘ê·¼ì„ í†µí•œ ê¸°ì‚¬ ìˆ˜ì§‘ì„ í—ˆìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìžˆìŠµë‹ˆë‹¤.")