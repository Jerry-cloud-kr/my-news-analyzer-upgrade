import streamlit as st
from newspaper import Article, Config
from sentence_transformers import SentenceTransformer, util
import openai
from openai import OpenAI
import google.generativeai as genai
import feedparser
import requests

# --- API Key ë° í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€) ---
client_openai = None 
OPENAI_API_KEY_Direct_Placeholder = "YOUR_OPENAI_KEY_PLACEHOLDER" 
# ... (OpenAI API í‚¤ ì„¤ì • ë¡œì§ ì „ì²´ ë³µì‚¬) ...
try:
    OPENAI_API_KEY_FROM_SECRETS = st.secrets["OPENAI_API_KEY"]
    if not OPENAI_API_KEY_FROM_SECRETS:
         st.error("âš ï¸ OpenAI API í‚¤ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ ê°’ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
         st.stop()
    client_openai = OpenAI(api_key=OPENAI_API_KEY_FROM_SECRETS) 
except KeyError:
    if OPENAI_API_KEY_Direct_Placeholder == "YOUR_OPENAI_KEY_PLACEHOLDER" or not OPENAI_API_KEY_Direct_Placeholder:
        st.error("OpenAI API í‚¤ë¥¼ Secretsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ì½”ë“œ ìƒë‹¨ í”Œë ˆì´ìŠ¤í™€ë”ì— ì‹¤ì œ í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    else: 
        st.warning("ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© OpenAI API í‚¤ê°€ ì½”ë“œì— ì§ì ‘ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. GitHub í‘¸ì‹œ ì „ ë°˜ë“œì‹œ Secrets ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.", icon="â—")
        client_openai = OpenAI(api_key=OPENAI_API_KEY_Direct_Placeholder)
except Exception as e:
    st.error(f"OpenAI API í‚¤/í´ë¼ì´ì–¸íŠ¸ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()
if client_openai is None: 
    st.error("OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨. API í‚¤ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
    st.stop()

GOOGLE_AI_API_KEY_Direct_Placeholder = "YOUR_GOOGLE_AI_KEY_PLACEHOLDER" 
try:
    GOOGLE_AI_API_KEY_FROM_SECRETS = st.secrets["GOOGLE_AI_API_KEY"]
    if not GOOGLE_AI_API_KEY_FROM_SECRETS:
         st.error("âš ï¸ Google AI API í‚¤ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì—ˆìœ¼ë‚˜ ê°’ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
         st.stop()
    genai.configure(api_key=GOOGLE_AI_API_KEY_FROM_SECRETS)
except KeyError:
    if GOOGLE_AI_API_KEY_Direct_Placeholder == "YOUR_GOOGLE_AI_KEY_PLACEHOLDER" or not GOOGLE_AI_API_KEY_Direct_Placeholder:
        st.error("Google AI API í‚¤ë¥¼ Secretsì—ì„œ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë¡œì»¬ í…ŒìŠ¤íŠ¸ ì‹œ ì½”ë“œ ìƒë‹¨ í”Œë ˆì´ìŠ¤í™€ë”ì— ì‹¤ì œ í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        st.stop()
    else: 
        st.warning("ë¡œì»¬ í…ŒìŠ¤íŠ¸ìš© Google AI API í‚¤ê°€ ì½”ë“œì— ì§ì ‘ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤. GitHub í‘¸ì‹œ ì „ ë°˜ë“œì‹œ Secrets ë°©ì‹ìœ¼ë¡œ ë³€ê²½í•˜ì„¸ìš”.", icon="â—")
        genai.configure(api_key=GOOGLE_AI_API_KEY_Direct_Placeholder)
except Exception as e:
    st.error(f"Google AI API í‚¤ ì„¤ì • ì˜¤ë¥˜: {e}")
    st.stop()

# --- Helper Functions ---
@st.cache_data
def get_final_url(url, timeout=10):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    try:
        response = requests.get(url, headers=headers, timeout=timeout, allow_redirects=True)
        response.raise_for_status()
        return response.url
    except requests.exceptions.RequestException as e:
        print(f"ìµœì¢… URL ìš”ì²­ ì¤‘ ì˜¤ë¥˜ ({url}): {e}")
        return url 
    except Exception as e:
        print(f"ìµœì¢… URL í™•ì¸ ì¤‘ ê¸°íƒ€ ì˜¤ë¥˜ ({url}): {e}")
        return url

# --- AI ê¸°ëŠ¥ í•¨ìˆ˜ë“¤ (ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€) ---
def summarize_text_gemini(text_content):
    # ... (ì´ì „ summarize_text_gemini í•¨ìˆ˜ ë‚´ìš© ê·¸ëŒ€ë¡œ) ...
    model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest', system_instruction="ë„ˆëŠ” ë‰´ìŠ¤ ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ê°ê´€ì ìœ¼ë¡œ ìš”ì•½í•˜ëŠ” AIì•¼.")
    prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì„ ê°ê´€ì ì¸ ì‚¬ì‹¤ì— ê¸°ë°˜í•˜ì—¬ í•µì‹¬ ë‚´ìš© ì¤‘ì‹¬ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì‹­ì‹œì˜¤. ìš”ì•½ì—ëŠ” ì£¼ìš” ì¸ë¬¼, ë°œìƒí•œ ì‚¬ê±´, ì¤‘ìš”í•œ ë°œì–¸, ê·¸ë¦¬ê³  ì‚¬ê±´ì˜ ë°°ê²½ ì •ë³´ê°€ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤. ì£¼ê´€ì ì¸ í•´ì„, í‰ê°€, ë˜ëŠ” ê¸°ì‚¬ì— ëª…ì‹œì ìœ¼ë¡œ ë“œëŸ¬ë‚˜ì§€ ì•Šì€ ì¶”ë¡ ì€ ë°°ì œí•˜ê³ , ì‚¬ì‹¤ ê´€ê³„ë¥¼ ëª…í™•íˆ ì „ë‹¬í•˜ëŠ” ë° ì§‘ì¤‘í•´ ì£¼ì‹­ì‹œì˜¤. ë¶„ëŸ‰ì€ í•œêµ­ì–´ ê¸°ì¤€ìœ¼ë¡œ ì•½ 3~5ë¬¸ì¥ (ë˜ëŠ” 100~150 ë‹¨ì–´) ì •ë„ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•´ ì£¼ì‹­ì‹œì˜¤.\n\nê¸°ì‚¬:\n{text_content}"
    try:
        response = model.generate_content(prompt,generation_config=genai.types.GenerationConfig(temperature=0.3))
        return response.text.strip()
    except Exception as e:
        st.warning("Gemini ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"Gemini ìš”ì•½ API ì˜¤ë¥˜: {e}")
        return "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

def detect_bias_openai(title, text_content):
    # ... (ì´ì „ detect_bias_openai í•¨ìˆ˜ ë‚´ìš© ê·¸ëŒ€ë¡œ) ...
    prompt = f"ë‹¤ìŒì€ ë‰´ìŠ¤ ì œëª©ê³¼ ë³¸ë¬¸ì…ë‹ˆë‹¤. ì œëª©ì´ ë³¸ë¬¸ ë‚´ìš©ì„ ì¶©ë¶„íˆ ë°˜ì˜í•˜ê³  ìˆëŠ”ì§€, ì¤‘ìš”í•œ ë§¥ë½ì´ë‚˜ ì¸ë¬¼ì˜ ì…ì¥ì´ ì™œê³¡ë˜ê±°ë‚˜ ëˆ„ë½ë˜ì—ˆëŠ”ì§€ íŒë‹¨í•´ì¤˜.\n\nì œëª©: {title}\në³¸ë¬¸: {text_content}\n\në¶„ì„ ê²°ê³¼ë¥¼ ê°„ë‹¨íˆ 3~5ì¤„ë¡œ ì •ë¦¬í•´ì¤˜."
    try:
        completion = client_openai.chat.completions.create(model="gpt-4", messages=[{"role": "system", "content": "ë„ˆëŠ” ê³µì •í•œ ë‰´ìŠ¤ í”„ë ˆì´ë° ë¶„ì„ ë„ìš°ë¯¸ì•¼."}, {"role": "user", "content": prompt}])
        return completion.choices[0].message.content.strip()
    except Exception as e:
        st.warning("OpenAI í”„ë ˆì´ë° ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        print(f"OpenAI í”„ë ˆì´ë° ë¶„ì„ API ì˜¤ë¥˜: {e}")
        return "í”„ë ˆì´ë° ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."

def extract_keywords_gemini(article_text):
    # ... (ì´ì „ extract_keywords_gemini í•¨ìˆ˜ ë‚´ìš© ê·¸ëŒ€ë¡œ) ...
    model = genai.GenerativeModel(model_name='gemini-1.5-flash-latest', system_instruction="You are an AI assistant specialized in extracting the most important keywords from news articles. Keywords should be nouns or core noun phrases. Respond only with the keywords, separated by commas.")
    user_prompt = f"ë‹¤ìŒ ë‰´ìŠ¤ ê¸°ì‚¬ ë³¸ë¬¸ì—ì„œ ê°€ì¥ ì¤‘ìš”í•œ í•µì‹¬ í‚¤ì›Œë“œë¥¼ 5ê°œë§Œ ì¶”ì¶œí•˜ì—¬, ê° í‚¤ì›Œë“œë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•œ í•˜ë‚˜ì˜ ë¬¸ìì—´ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì´ë‚˜ ë¬¸ì¥ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.\n\nì˜ˆì‹œ ì‘ë‹µ:\ní‚¤ì›Œë“œ1,í•µì‹¬ ë‹¨ì–´,ì„¸ë²ˆì§¸ í‚¤ì›Œë“œ,ì¤‘ìš” ê°œë…,ë§ˆì§€ë§‰\n\nê¸°ì‚¬ ë³¸ë¬¸:\n{article_text}"
    try:
        response = model.generate_content(user_prompt, generation_config=genai.types.GenerationConfig(temperature=0.2))
        keywords_string = response.text.strip()
        if keywords_string:
            if "\n" in keywords_string: keywords_string = keywords_string.split("\n")[-1]
            if ":" in keywords_string: keywords_string = keywords_string.split(":")[-1].strip()
            return [kw.strip() for kw in keywords_string.split(',') if kw.strip()]
        return []
    except Exception as e:
        print(f"Gemini í‚¤ì›Œë“œ ì¶”ì¶œ API ì˜¤ë¥˜: {e}")
        st.warning("AI í‚¤ì›Œë“œ ì¶”ì¶œ ì¤‘ ì¼ì‹œì ì¸ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        return []

# --- ìœ ì‚¬ë„ ì¸¡ì • ëª¨ë¸ ë¡œë“œ (í™œì„±í™”) ---
model_similarity = None 
try:
    model_similarity = SentenceTransformer('all-MiniLM-L6-v2', device='cpu') 
    if model_similarity:
        print("SentenceTransformer ëª¨ë¸ ë¡œë“œ ì„±ê³µ!") 
    else: 
        st.error("SentenceTransformer ëª¨ë¸ ë¡œë“œì— ì‹¤íŒ¨í–ˆìœ¼ë‚˜ ëª…ì‹œì  ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì•± ì‹¤í–‰ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        st.stop()
except Exception as e:
    st.error(f"SentenceTransformer ëª¨ë¸ ë¡œë“œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
    st.error("íŒ: ì´ ì˜¤ë¥˜ëŠ” ë³´í†µ torch, torchvision, torchaudio ë˜ëŠ” sentence-transformers ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜/í˜¸í™˜ì„± ë¬¸ì œì…ë‹ˆë‹¤.")
    st.error("ì•±ì˜ Python ë²„ì „(Streamlit Cloud ì„¤ì •), requirements.txt (torch í¬í•¨ ì—¬ë¶€), packages.txt (lxml ì‹œìŠ¤í…œ ì˜ì¡´ì„±)ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    st.stop()

# --- ê¸°ì‚¬ ë¶„ì„ ë° ê²°ê³¼ í‘œì‹œ í•¨ìˆ˜ (ì´ì „ ì½”ë“œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€) ---
def display_article_analysis_content(title_to_display, text_content, article_url):
    # ... (ì´ì „ display_article_analysis_content í•¨ìˆ˜ ë‚´ìš© ê·¸ëŒ€ë¡œ, ìœ ì‚¬ë„ ë¶„ì„ í¬í•¨) ...
    st.markdown("---")
    st.subheader("ğŸ“° ê¸°ì‚¬ ì œëª©")
    st.write(f"**{title_to_display}**")
    st.markdown(f"[ğŸ”— ê¸°ì‚¬ ì›ë¬¸ ë°”ë¡œê°€ê¸°]({article_url})", unsafe_allow_html=True)
    st.markdown("---")

    st.subheader("ğŸ§¾ ë³¸ë¬¸ ìš”ì•½ (by Gemini AI)")
    with st.expander("âš ï¸ AI ìš”ì•½ì— ëŒ€í•œ ì¤‘ìš” ì•ˆë‚´ (í´ë¦­í•˜ì—¬ í™•ì¸)", expanded=False):
        st.markdown(""" **ì£¼ì˜: AI ê¸°ë°˜ ìš”ì•½ (Gemini)**\n\n* ë³¸ ìš”ì•½ì€ Gemini ëª¨ë¸ì„ í†µí•´ ìƒì„±ë˜ì—ˆìœ¼ë©°, ê¸°ì‚¬ì˜ ëª¨ë“  ë‚´ìš©ì„ ì™„ë²½í•˜ê²Œ ë°˜ì˜í•˜ì§€ ëª»í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n* AIëŠ” í•™ìŠµ ë°ì´í„°ì˜ í•œê³„ë‚˜ ìš”ì•½ ê³¼ì •ì˜ íŠ¹ì„±ìœ¼ë¡œ ì¸í•´ ë•Œë•Œë¡œ ë¶€ì •í™•í•œ ë‚´ìš©ì„ ì „ë‹¬í•˜ê±°ë‚˜ ì¤‘ìš”í•œ ë‚´ìš©ì„ ìƒëµí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n* ì œê³µëœ ìš”ì•½ì€ ê¸°ì‚¬ì˜ í•µì‹¬ ë‚´ìš©ì„ ë¹ ë¥´ê²Œ íŒŒì•…í•˜ê¸° ìœ„í•œ ì°¸ê³  ìë£Œë¡œë§Œ í™œìš©í•´ì£¼ì‹­ì‹œì˜¤.\n* ê¸°ì‚¬ì˜ ì „ì²´ì ì¸ ë§¥ë½ê³¼ ì •í™•í•œ ì •ë³´ í™•ì¸ì„ ìœ„í•´ì„œëŠ” ë°˜ë“œì‹œ ì›ë¬¸ ê¸°ì‚¬ë¥¼ í•¨ê»˜ ì½ì–´ë³´ì‹œëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë©°, ìµœì¢…ì ì¸ ë‚´ìš©ì— ëŒ€í•œ íŒë‹¨ì€ ì‚¬ìš©ìì˜ ì±…ì„ì…ë‹ˆë‹¤. """)
    body_summary = summarize_text_gemini(text_content)
    if body_summary == "ìš”ì•½ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.": st.error(body_summary)
    else: st.write(body_summary)
    st.markdown("---")

    st.subheader("ğŸ” AI ì¶”ì¶œ ì£¼ìš” í‚¤ì›Œë“œì™€ ì œëª© ë¹„êµ (by Gemini AI)")
    extracted_keywords = extract_keywords_gemini(text_content)
    if not extracted_keywords:
        st.info("â„¹ï¸ AIê°€ ë³¸ë¬¸ì—ì„œ ì£¼ìš” í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆê±°ë‚˜, ì¶”ì¶œëœ í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
    else:
        st.caption(f"AI(Gemini)ê°€ ë³¸ë¬¸ì—ì„œ ì¶”ì¶œí•œ ì£¼ìš” í‚¤ì›Œë“œ: **{', '.join(extracted_keywords)}**")
        missing_in_title = [kw for kw in extracted_keywords if kw.lower() not in title_to_display.lower()]
        if missing_in_title:
            st.warning(f"â— AI ì¶”ì¶œ í‚¤ì›Œë“œ ì¤‘ ì¼ë¶€ê°€ ì œëª©ì— ë¹ ì ¸ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤: **{', '.join(missing_in_title)}**")
        else:
            st.success("âœ… AI ì¶”ì¶œ í•µì‹¬ í‚¤ì›Œë“œê°€ ì œëª©ì— ì˜ ë°˜ì˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
    st.markdown("---")
    
    st.subheader("ğŸ“Š ì œëª©-ë³¸ë¬¸ìš”ì•½ ìœ ì‚¬ë„ íŒë‹¨")
    if model_similarity is not None: 
        try:
            embeddings = model_similarity.encode([title_to_display, body_summary], convert_to_tensor=True)
            similarity = util.pytorch_cos_sim(embeddings[0], embeddings[1]).item()
            
            similarity_threshold_high = 0.65; similarity_threshold_mid = 0.40
            if similarity > similarity_threshold_high: result_text, result_color = "âœ… **ë†’ìŒ**: ì œëª©ì´ ë³¸ë¬¸ ìš”ì•½ ë‚´ìš©ì„ ì˜ ë°˜ì˜í•˜ê³  ìˆìŠµë‹ˆë‹¤.", "green"
            elif similarity > similarity_threshold_mid: result_text, result_color = "ğŸŸ¡ **ì¤‘ê°„**: ì œëª©ì´ ë³¸ë¬¸ ìš”ì•½ê³¼ ë‹¤ì†Œ ê´€ë ¨ì€ ìˆì§€ë§Œ, ë‚´ìš©ì´ ì•½ê°„ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.", "orange"
            else: result_text, result_color = "âš ï¸ **ë‚®ìŒ**: ì œëª©ì´ ë³¸ë¬¸ ìš”ì•½ ë‚´ìš©ê³¼ ë§ì´ ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë‚šì‹œì„±ì´ê±°ë‚˜ ë‹¤ë¥¸ ë‚´ìš©ì„ ë‹¤ë£° ê°€ëŠ¥ì„±ì„ í™•ì¸í•´ë³´ì„¸ìš”.", "red"
            
            st.markdown(f"<span style='color:{result_color};'>{result_text}</span> (ìœ ì‚¬ë„ ì ìˆ˜: {similarity:.2f})", unsafe_allow_html=True)
            st.caption(f"ì°¸ê³ : ìœ ì‚¬ë„ëŠ” ì œëª©ê³¼ AI ìš”ì•½ë¬¸ ê°„ì˜ ì˜ë¯¸ì  ê´€ê³„ë¥¼ ë‚˜íƒ€ë‚´ë©°, ì„ê³„ê°’(í˜„ì¬: ë†’ìŒ {similarity_threshold_high}, ì¤‘ê°„ {similarity_threshold_mid})ì— ë”°ë¼ í•´ì„ì´ ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        except Exception as e_sim:
            st.error(f"ìœ ì‚¬ë„ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e_sim}")
            print(f"ìœ ì‚¬ë„ ë¶„ì„ ì˜¤ë¥˜: {e_sim}")
            st.info("â„¹ï¸ ìœ ì‚¬ë„ ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else: 
        st.info("â„¹ï¸ ì œëª©-ë³¸ë¬¸ ìœ ì‚¬ë„ ë¶„ì„ ê¸°ëŠ¥ì€ SentenceTransformer ëª¨ë¸ ë¡œë“œ ë¬¸ì œë¡œ ì¸í•´ í˜„ì¬ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.") 
    st.markdown("---")

    st.subheader("ğŸ•µï¸ í”„ë ˆì´ë° ë¶„ì„ ê²°ê³¼ (by GPT)")
    with st.expander("âš ï¸ AI í”„ë ˆì´ë° ë¶„ì„ ì£¼ì˜ì‚¬í•­ (í´ë¦­í•˜ì—¬ í™•ì¸)"):
        st.markdown(""" **ì£¼ì˜: AI ê¸°ë°˜ í”„ë ˆì´ë° ë¶„ì„ (GPT)**\n\n* ë³¸ ë¶„ì„ì€ GPT ëª¨ë¸ì— ì˜í•´ ìˆ˜í–‰ë˜ì—ˆìœ¼ë©°, ì™„ë²½ì„±ì„ ë³´ì¥í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.\n* AIëŠ” ë°ì´í„°ì™€ í•™ìŠµ ë°©ì‹ì— ë”°ë¼ í¸í–¥ëœ ê²°ê³¼ë¥¼ ì œì‹œí•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.\n* ì œê³µëœ ë¶„ì„ì€ ì°¸ê³  ìë£Œë¡œ í™œìš©í•˜ì‹œê³ , ìµœì¢…ì ì¸ íŒë‹¨ì€ ì‚¬ìš©ìì˜ ì±…ì„í•˜ì— ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤. """)
    framing_result = detect_bias_openai(title_to_display, text_content)
    if framing_result == "í”„ë ˆì´ë° ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.": st.error(framing_result)
    else: st.info(framing_result)

# --- newspaper3k Config ê°ì²´ ---
NEWS_CONFIG = Config()
NEWS_CONFIG.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
NEWS_CONFIG.request_timeout = 15
NEWS_CONFIG.memoize_articles = False 
NEWS_CONFIG.fetch_images = False 

# --- Streamlit ì•± UI êµ¬ì„± ---
st.set_page_config(page_title="ë‰´ìŠ¤ì½ì€ì²™ë°©ì§€ê¸° (AI)", page_icon="ğŸ§")
st.title("ğŸ§ ë‰´ìŠ¤ì½ì€ì²™ë°©ì§€ê¸°")
st.write("í‚¤ì›Œë“œ ê²€ìƒ‰ ë˜ëŠ” URL ì§ì ‘ ì…ë ¥ìœ¼ë¡œ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ AIì™€ í•¨ê»˜ ë¶„ì„í•´ë³´ì„¸ìš”!")
st.caption("ë³¸ë¬¸ ìš”ì•½ ë° í‚¤ì›Œë“œ ì¶”ì¶œì€ Gemini AI, í”„ë ˆì´ë° ë¶„ì„ì€ OpenAI GPT, ìœ ì‚¬ë„ ë¶„ì„ì€ SentenceTransformerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")

input_method_options = ("í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰", "URL ì§ì ‘ ì…ë ¥")
if 'current_input_method' not in st.session_state:
    st.session_state.current_input_method = input_method_options[0] # ê¸°ë³¸ê°’ ì„¤ì •

st.session_state.current_input_method = st.radio(
    "ë‰´ìŠ¤ ê°€ì ¸ì˜¤ëŠ” ë°©ë²• ì„ íƒ:",
    options=input_method_options,
    key="input_method_selector", # key ë³€ê²½
    horizontal=True,
    index=input_method_options.index(st.session_state.current_input_method) # ì„ íƒ ìœ ì§€
)

if st.session_state.current_input_method == "í‚¤ì›Œë“œë¡œ Google News ê²€ìƒ‰":
    st.subheader("ğŸ—‚ï¸ í‚¤ì›Œë“œë¡œ ë‰´ìŠ¤ ì°¾ì•„ë³´ê¸°") # í—¤ë” ë³€ê²½
    search_query = st.text_input("ê²€ìƒ‰í•  í‚¤ì›Œë“œë¥¼ ì…ë ¥í•˜ì„¸ìš”:", placeholder="ì˜ˆ: ê¸€ë¡œë²Œ ê²½ì œ ë™í–¥", key="keyword_search_input_main")

    if st.button("ğŸ” ë‰´ìŠ¤ ê²€ìƒ‰", key="search_button_main_action", use_container_width=True):
        if not search_query:
            st.warning("ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
        else:
            st.session_state.article_options_display = None # ì´ì „ ê²°ê³¼ ì´ˆê¸°í™”
            google_news_rss_url = f"https://news.google.com/rss/search?q={search_query}&hl=ko&gl=KR&ceid=KR:ko"
            fetched_articles_for_display = [] # ì—¬ê¸°ì— (ì œëª©, ìµœì¢… URL) íŠœí”Œ ì €ì¥
            try:
                custom_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
                with st.spinner(f"'{search_query}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ Google Newsì—ì„œ ê²€ìƒ‰í•˜ê³  ë§í¬ë¥¼ í™•ì¸ ì¤‘..."):
                    feed = feedparser.parse(google_news_rss_url, agent=custom_user_agent)
                    if feed.entries:
                        for entry in feed.entries[:10]: # ê°€ì ¸ì˜¬ ê¸°ì‚¬ ìˆ˜ ì¤„ì—¬ì„œ í…ŒìŠ¤íŠ¸ (ì˜ˆ: 10ê°œ)
                            if hasattr(entry, 'title') and hasattr(entry, 'link'):
                                final_url = get_final_url(entry.link) # ê° ë§í¬ì˜ ìµœì¢… ëª©ì ì§€ í™•ì¸
                                if final_url: # ìµœì¢… URLì´ ìˆì„ ê²½ìš°ì—ë§Œ ì¶”ê°€
                                    fetched_articles_for_display.append({"title": entry.title, "url": final_url})
                        if fetched_articles_for_display:
                             st.success(f"'{search_query}' ê´€ë ¨ ë‰´ìŠ¤ {len(fetched_articles_for_display)}ê±´ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
                        else:
                            st.warning(f"'{search_query}' ê´€ë ¨ Google Newsì—ì„œ ìœ íš¨í•œ ê¸°ì‚¬ ë§í¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜, ê¸°ì‚¬ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                    else:
                        st.warning(f"'{search_query}' ê´€ë ¨ Google Newsì—ì„œ ê¸°ì‚¬ë¥¼ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. (HTTP Status: {feed.get('status', 'N/A')})")
            except Exception as e:
                st.error(f"ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            
            if fetched_articles_for_display:
                st.session_state.article_options_display = fetched_articles_for_display
            else: 
                if 'article_options_display' in st.session_state:
                    del st.session_state.article_options_display
    
    if 'article_options_display' in st.session_state and st.session_state.article_options_display:
        st.markdown("---")
        st.write("ğŸ‘‡ ë¶„ì„í•  ê¸°ì‚¬ì˜ ì›ë¬¸ ë§í¬ë¥¼ í´ë¦­í•˜ì—¬ ë‚´ìš©ì„ í™•ì¸ í›„, 'URL ì§ì ‘ ì…ë ¥/ë¶„ì„' íƒ­ì— ë¶™ì—¬ë„£ì–´ ë¶„ì„í•´ì£¼ì„¸ìš”.")
        for item in st.session_state.article_options_display:
            st.markdown(f"- [{item['title']}]({item['url']})")
        st.info("ì›í•˜ëŠ” ê¸°ì‚¬ì˜ ë§í¬ë¥¼ ë³µì‚¬í•˜ì—¬ 'URL ì§ì ‘ ì…ë ¥/ë¶„ì„' íƒ­ì—ì„œ ë¶„ì„ì„ ì§„í–‰í•´ì£¼ì„¸ìš”.")


elif st.session_state.current_input_method == "URL ì§ì ‘ ì…ë ¥": # input_method ëŒ€ì‹  st.session_state.current_input_method ì‚¬ìš©
    st.subheader("ğŸ”— URL ì§ì ‘ ì…ë ¥í•˜ì—¬ ë¶„ì„í•˜ê¸°")
    
    # ğŸ‘‡ URLì„ ì…ë ¥ë°›ì•„ 'url_direct_input' ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
    url_direct_input = st.text_input(
        "ë¶„ì„í•  ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì „ì²´ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”:", 
        placeholder="ì˜ˆ: https://www.example-news.com/news/article123", 
        key="url_direct_input_main_field" # ì´ keyëŠ” ìœ„ì ¯ ì‹ë³„ìš©ì…ë‹ˆë‹¤.
    )

    if st.button("ğŸš€ URL ë¶„ì„ ì‹œì‘", use_container_width=True, key="direct_url_analyze_button_main_action"): # ë²„íŠ¼ key ì´ë¦„ì€ ì´ì „ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€
        st.write("--- ë²„íŠ¼ í´ë¦­ë¨, ë¶„ì„ ë¡œì§ ì‹œì‘ì  ---") 

        # ğŸ‘‡ ì—¬ê¸°ì„œë¶€í„° ëª¨ë“  'url_direct_input_tab2'ë¥¼ 'url_direct_input'ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
        if not url_direct_input: 
            st.warning("ë¶„ì„í•  ê¸°ì‚¬ì˜ URLì„ ì…ë ¥í•´ì£¼ì„¸ìš”.")
            st.write("--- URL ì—†ìŒ ---") 
        elif not (url_direct_input.startswith('http://') or url_direct_input.startswith('https://')):
            st.warning("ì˜¬ë°”ë¥¸ URL í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. 'http://' ë˜ëŠ” 'https://'ë¡œ ì‹œì‘í•´ì•¼ í•©ë‹ˆë‹¤.")
            st.write("--- URL í˜•ì‹ ì˜¤ë¥˜ ---") 
        else:
            st.write(f"--- URL ìœ íš¨ì„± í†µê³¼: {url_direct_input} ---") 
            
            final_url_to_process = get_final_url(url_direct_input) # get_final_url í•¨ìˆ˜ í˜¸ì¶œ ì‹œì—ë„ ì˜¬ë°”ë¥¸ ë³€ìˆ˜ ì‚¬ìš©
            st.info(f"ì…ë ¥í•˜ì‹  URLì˜ ê¸°ì‚¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤: {final_url_to_process}") # ì—¬ê¸°ì„œë„ final_url_to_process ì‚¬ìš©
            
            try:
                with st.spinner(f"ê¸°ì‚¬ë¥¼ ê°€ì ¸ì™€ AIê°€ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤..."):
                    # final_url_to_processë¥¼ Article ê°ì²´ì— ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤.
                    article = Article(final_url_to_process, config=NEWS_CONFIG, language='ko') 
                    article.download()
                    article.parse()
                    # --- ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€ ì‹œì‘ ---
                    st.markdown("--- newspaper3k ë””ë²„ê¹… ì •ë³´ ---")
                    st.write(f"**Article ê°ì²´ ìƒì„± ì‹œ ì‚¬ìš©ëœ URL:** `{final_url_to_process}`") # ì´ì „ì— final_url_to_processë¡œ ë³€ê²½í–ˆì—ˆìŒ
                    st.write(f"**`article.download_state`:** {article.download_state} (2ì—¬ì•¼ ì„±ê³µ)")
                    
                    if article.html:
                        st.text_area("ë‹¤ìš´ë¡œë“œëœ HTML ì•ë¶€ë¶„ (500ì):", article.html[:500], height=150)
                    else:
                        st.write("ë‹¤ìš´ë¡œë“œëœ HTML ë‚´ìš©ì´ ì—†ìŠµë‹ˆë‹¤.")
                    
                    st.write(f"**`article.title` (íŒŒì‹± í›„):** {article.title}")
                    st.write(f"**`len(article.text)` (íŒŒì‹± í›„):** {len(article.text)}")
                    if article.text:
                        st.write(f"**7. `newspaper3k`ë¡œ íŒŒì‹±ëœ í…ìŠ¤íŠ¸ (ì• 100ì):** `{article.text[:100].replace(':', '')}...`")
                    st.markdown("--- ë””ë²„ê¹… ì •ë³´ ë ---")
                    # --- ë””ë²„ê¹… ë¡œê·¸ ì¶”ê°€ ë ---

                    if not article.title or not article.text or len(article.text) < 50:
                        st.error("ê¸°ì‚¬ ì œëª©ì´ë‚˜ ë³¸ë¬¸ì„ ê°€ì ¸ì˜¤ì§€ ëª»í–ˆê±°ë‚˜ ë‚´ìš©ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ URLì„ ì‹œë„í•´ì£¼ì„¸ìš”.")
                    else:
                        display_article_analysis_content(article.title, article.text, final_url_to_process) # final_url_to_process ì‚¬ìš©
            except Exception as e:
                st.error(f"URL ê¸°ì‚¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                print(f"ì „ì²´ ì˜¤ë¥˜: {e}") 
                st.caption("URLì„ í™•ì¸í•˜ì‹œê±°ë‚˜, ë‹¤ë¥¸ ê¸°ì‚¬ë¥¼ ì‹œë„í•´ë³´ì„¸ìš”. ì¼ë¶€ ì›¹ì‚¬ì´íŠ¸ëŠ” ì™¸ë¶€ ì ‘ê·¼ì„ í†µí•œ ê¸°ì‚¬ ìˆ˜ì§‘ì„ í—ˆìš©í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
